{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from src.document import Document\n",
    "from src.stylometry_extractor import StylometryExtractor\n",
    "from src.text_chunk import TextChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "84W9sB9t4pXM"
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    data = []\n",
    "\n",
    "    for i in itertools.count(start=1):\n",
    "        try:\n",
    "            text = open(os.path.join(path, 'problem-' + str(i) + '.txt'), 'r').read()\n",
    "            changes = json.load(open(os.path.join(path, 'problem-' + str(i) + '.truth')))\n",
    "            data.append(Document(text, **changes))\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DTcHTwvH5C8h"
   },
   "outputs": [],
   "source": [
    "train = get_data('../data/train_raw')\n",
    "validation = get_data('../data/validation_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_chunks_csv(documents, csv_out):\n",
    "    new_train = []\n",
    "    for d in documents:\n",
    "        indices = []\n",
    "        if not d.has_changes:\n",
    "            indices = [None, len(d.sentences)//3, (len(d.sentences)//3)*2, None]\n",
    "        else:\n",
    "            indices = [None] + d.sent_positions + [None]\n",
    "\n",
    "        cache = {}\n",
    "        for i, j in zip(indices[:-1], indices[1:]):\n",
    "            cache['{} {}'.format(i,j)] = ' '.join(d.sentences[i:j])\n",
    "\n",
    "        rows = [\n",
    "            (\n",
    "                cache['{} {}'.format(i,j)],\n",
    "                cache['{} {}'.format(j,k)],\n",
    "                d.has_changes\n",
    "            ) for i, j, k in zip(indices[:-2], indices[1:-1], indices[2:])\n",
    "        ]\n",
    "\n",
    "        new_train.extend(rows)\n",
    "\n",
    "    with open(csv_out, 'w') as out:\n",
    "        csv_out = csv.writer(out)\n",
    "        for row in new_train:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '../data/train_chunks.csv'\n",
    "if not os.path.exists(csv_name):\n",
    "    gen_chunks_csv(validation, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '../data/validation_chunks.csv'\n",
    "if not os.path.exists(csv_name):\n",
    "    gen_chunks_csv(validation, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features_df(documents):\n",
    "    rows = []\n",
    "    for d in documents:\n",
    "        indices = []\n",
    "        if not d.has_changes:\n",
    "            indices = [None, len(d.sentences)//3, (len(d.sentences)//3)*2, None]\n",
    "        else:\n",
    "            indices = [None] + d.sent_positions + [None]\n",
    "\n",
    "        cache = {}\n",
    "        for i, j in zip(indices[:-1], indices[1:]):\n",
    "            cache['{} {}'.format(i,j)] = TextChunk(' '.join(d.sentences[i:j]))\n",
    "\n",
    "        for i, j, k in zip(indices[:-2], indices[1:-1], indices[2:]):\n",
    "            diff_dict = (cache['{} {}'.format(i,j)]\n",
    "                         .absolute_difference_with(cache['{} {}'.format(j,k)]))\n",
    "            diff_dict['different_author'] = d.has_changes\n",
    "            rows.append(pd.Series(diff_dict))\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '../data/train_chunks_features.csv'\n",
    "df_train = None\n",
    "if os.path.exists(csv_name):\n",
    "    df_train = pd.read_csv(csv_name)\n",
    "else:\n",
    "    df_train = gen_features_df(train)\n",
    "    df_train.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564.084117512164"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train[\"you're\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '../data/validation_chunks_features.csv'\n",
    "df_validation = None\n",
    "if os.path.exists(csv_name):\n",
    "    df_validation = pd.read_csv(csv_name)\n",
    "else:\n",
    "    df_validation = gen_features_df(validation)\n",
    "    df_validation.to_csv(csv_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
