{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and serialize scaler and final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import dill\n",
    "import itertools\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine, braycurtis, canberra, cityblock, chebyshev, minkowski\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from src.document import Document    \n",
    "from src.text_chunk import TextChunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a model and saving it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import train / val as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_features_scaled_standard.csv', index_col=0)\n",
    "val = pd.read_csv('../data/validation_features_scaled_standard.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_FEATURES = int((train.shape[1] - 1) / 2)\n",
    "assert number_of_features == 938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define similarity/distance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minmax(a, b):\n",
    "    return sum(np.minimum(a, b)) / sum(np.maximum(a, b))\n",
    "\n",
    "def similarities(vectors):\n",
    "    a = [vectors['A_{}'.format(i)] for i in range(NUMBER_OF_FEATURES)]\n",
    "    b = [vectors['B_{}'.format(i)] for i in range(NUMBER_OF_FEATURES)]\n",
    "    \n",
    "    return (minmax(a,b),\n",
    "            cosine(a, b),\n",
    "            braycurtis(a, b),\n",
    "            canberra(a, b),\n",
    "            cityblock(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - SVC based on all similarity measures, all features, no weights, standard scaling + final standard scaling of calculated similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_measures = ['minmax_similarity', 'cosine_distance', 'braycurtis_distance',\n",
    "                               'canberra_distance', 'cityblock_distance']\n",
    "\n",
    "# computing train similarity measures\n",
    "train_similarities = train.apply(lambda vectors: similarities(vectors), axis=1).apply(pd.Series)\n",
    "train_similarities.columns = similarity_measures\n",
    "train_similarities['different_author'] = train['different_author']\n",
    "\n",
    "# computing val similarity measures\n",
    "val_similarities = val.apply(lambda vectors: similarities(vectors), axis=1).apply(pd.Series)\n",
    "val_similarities.columns = similarity_measures\n",
    "val_similarities['different_author'] = val['different_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minmax_similarity</th>\n",
       "      <th>cosine_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>different_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.055474</td>\n",
       "      <td>0.912823</td>\n",
       "      <td>0.716960</td>\n",
       "      <td>398.480153</td>\n",
       "      <td>605.604589</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.053584</td>\n",
       "      <td>0.916162</td>\n",
       "      <td>0.721877</td>\n",
       "      <td>400.251424</td>\n",
       "      <td>608.193625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.205837</td>\n",
       "      <td>0.937646</td>\n",
       "      <td>0.647488</td>\n",
       "      <td>289.809889</td>\n",
       "      <td>619.982495</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.049284</td>\n",
       "      <td>0.763965</td>\n",
       "      <td>0.597759</td>\n",
       "      <td>326.068801</td>\n",
       "      <td>566.108841</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.714360</td>\n",
       "      <td>0.733612</td>\n",
       "      <td>0.650287</td>\n",
       "      <td>393.313379</td>\n",
       "      <td>560.358946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minmax_similarity  cosine_distance  braycurtis_distance  canberra_distance  \\\n",
       "0          -1.055474         0.912823             0.716960         398.480153   \n",
       "1          -1.053584         0.916162             0.721877         400.251424   \n",
       "2          -1.205837         0.937646             0.647488         289.809889   \n",
       "3          -1.049284         0.763965             0.597759         326.068801   \n",
       "4          -0.714360         0.733612             0.650287         393.313379   \n",
       "\n",
       "   cityblock_distance  different_author  \n",
       "0          605.604589              True  \n",
       "1          608.193625              True  \n",
       "2          619.982495              True  \n",
       "3          566.108841             False  \n",
       "4          560.358946             False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_similarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_x = train_similarities[similarity_measures]\n",
    "t_y = train_similarities['different_author']\n",
    "v_x = val_similarities[similarity_measures]\n",
    "v_y = val_similarities['different_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarities_scaler = StandardScaler()\n",
    "similarities_scaler.fit(t_x)\n",
    "t_x = similarities_scaler.transform(t_x)\n",
    "v_x = similarities_scaler.transform(v_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.783779207586\n",
      "val accuracy:  0.779416809605\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(t_x, t_y)\n",
    "\n",
    "print('train accuracy: ', (svc.predict(t_x) == t_y).mean())\n",
    "print('val accuracy: ', (svc.predict(v_x) == v_y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/similarities_scaler.pk', 'wb') as f:\n",
    "    dill.dump(similarities_scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save SVC model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/svc.pk', 'wb') as f:\n",
    "    dill.dump(svc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluate model on final task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load needed models and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/standard_scaler.pk', 'rb') as f:\n",
    "    VECTORS_SCALER = dill.load(f)\n",
    "    \n",
    "with open('../data/similarities_scaler.pk', 'rb') as f:\n",
    "    SIMILARITIES_SCALER = dill.load(f)\n",
    "    \n",
    "with open('../data/svc.pk', 'rb') as f:\n",
    "    SVC = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import raw docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    data = []\n",
    "\n",
    "    for i in itertools.count(start=1):\n",
    "        try:\n",
    "            text = open(os.path.join(path, 'problem-' + str(i) + '.txt'), 'r').read()\n",
    "            changes = json.load(open(os.path.join(path, 'problem-' + str(i) + '.truth')))\n",
    "            data.append(Document(text, **changes))\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_docs = get_data('../data/train_raw')\n",
    "validation_docs = get_data('../data/validation_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarities(a, b):\n",
    "    return (minmax(a,b),\n",
    "            cosine(a, b),\n",
    "            braycurtis(a, b),\n",
    "            canberra(a, b),\n",
    "            cityblock(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_document(document):\n",
    "    \"\"\"\n",
    "    Splits a document to 3 chunks with equal number of sentences.\n",
    "    Calculates similarities between each pair of chunks and predicts different author for each pair.\n",
    "    Returns True if any pair has a different author.\n",
    "    \"\"\"\n",
    "    splits = [None, len(document.sentences)//3, (len(document.sentences)//3)*2, None]\n",
    "    chunks = [TextChunk(' '.join(document.sentences[start:end]))\n",
    "              for start, end in zip(splits[:-1], splits[1:])]\n",
    "    vectors = map(lambda chunk: VECTORS_SCALER.transform(chunk.to_vector()), chunks)\n",
    "    chunk_similarities = pd.DataFrame(columns=similarity_measures)\n",
    "    \n",
    "    for first_vector, second_vector in combinations(vectors, 2):\n",
    "        chunk_similarities.loc[len(chunk_similarities)] = similarities(first_vector, second_vector)\n",
    "        \n",
    "    chunk_similarities = SIMILARITIES_SCALER.transform(chunk_similarities)\n",
    "    \n",
    "    return any(SVC.predict(chunk_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in validation_docs:\n",
    "    document.predicted = classify_document(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = pd.Series([document.has_changes for document in validation_docs])\n",
    "predicted = pd.Series([document.predicted for document in validation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63806970509383376"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actual == predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same thing but classify documents as having a style change if at least two pairs of chunks are by a different author\n",
    "\n",
    "### Can't have only 1 pair (out of 3 pairs) with different author?!??!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_document(document):\n",
    "    \"\"\"\n",
    "    Splits a document to 3 chunks with equal number of sentences.\n",
    "    Calculates similarities between each pair of chunks and predicts different author for each pair.\n",
    "    Returns True if at least two pairs have a different author.\n",
    "    \"\"\"\n",
    "    splits = [None, len(document.sentences)//3, (len(document.sentences)//3)*2, None]\n",
    "    chunks = [TextChunk(' '.join(document.sentences[start:end]))\n",
    "              for start, end in zip(splits[:-1], splits[1:])]\n",
    "    vectors = map(lambda chunk: VECTORS_SCALER.transform(chunk.to_vector()), chunks)\n",
    "    chunk_similarities = pd.DataFrame(columns=similarity_measures)\n",
    "    \n",
    "    for first_vector, second_vector in combinations(vectors, 2):\n",
    "        chunk_similarities.loc[len(chunk_similarities)] = similarities(first_vector, second_vector)\n",
    "        \n",
    "    chunk_similarities = SIMILARITIES_SCALER.transform(chunk_similarities)\n",
    "    \n",
    "    return sum(SVC.predict(chunk_similarities)) >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for document in validation_docs:\n",
    "    document.predicted = classify_document(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = pd.Series([document.has_changes for document in validation_docs])\n",
    "predicted = pd.Series([document.predicted for document in validation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65683646112600536"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actual == predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try splitting document to parts with equal length (instead of equal number of sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_document(document):\n",
    "    \"\"\"\n",
    "    Splits a document to 3 chunks with equal length.\n",
    "    Calculates similarities between each pair of chunks and predicts different author for each pair.\n",
    "    Returns True if at least 2 pairs have a different author.\n",
    "    \"\"\"\n",
    "    document_length = len(document.text)\n",
    "    chunks = [TextChunk(document.text[:document_length//3]),\n",
    "              TextChunk(document.text[document_length//3:document_length//3*2]),\n",
    "              TextChunk(document.text[document_length//3*2:])]\n",
    "\n",
    "    vectors = map(lambda chunk: VECTORS_SCALER.transform(chunk.to_vector()), chunks)\n",
    "    chunk_similarities = pd.DataFrame(columns=similarity_measures)\n",
    "    \n",
    "    for first_vector, second_vector in combinations(vectors, 2):\n",
    "        chunk_similarities.loc[len(chunk_similarities)] = similarities(first_vector, second_vector)\n",
    "        \n",
    "    chunk_similarities = SIMILARITIES_SCALER.transform(chunk_similarities)\n",
    "    \n",
    "    return sum(SVC.predict(chunk_similarities)) >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in validation_docs:\n",
    "    document.predicted = classify_document(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = pd.Series([document.has_changes for document in validation_docs])\n",
    "predicted = pd.Series([document.predicted for document in validation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63538873994638068"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actual == predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to two parts with equal length (instead of 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_document(document):\n",
    "    \"\"\"\n",
    "    Splits a document to 2 chunks with equal length.\n",
    "    Calculates similarities between the two chunks and predicts different author.\n",
    "    Returns True if the predicted value for different author is True.\n",
    "    \"\"\"\n",
    "    document_length = len(document.text)\n",
    "    chunks = [TextChunk(document.text[:document_length//2]),\n",
    "              TextChunk(document.text[document_length//2:])]\n",
    "\n",
    "    vectors = map(lambda chunk: VECTORS_SCALER.transform(chunk.to_vector()), chunks)\n",
    "    chunk_similarities = pd.DataFrame(columns=similarity_measures)\n",
    "    \n",
    "    for first_vector, second_vector in combinations(vectors, 2):\n",
    "        chunk_similarities.loc[len(chunk_similarities)] = similarities(first_vector, second_vector)\n",
    "        \n",
    "    chunk_similarities = SIMILARITIES_SCALER.transform(chunk_similarities)\n",
    "    \n",
    "    return any(SVC.predict(chunk_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in validation_docs:\n",
    "    document.predicted = classify_document(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = pd.Series([document.has_changes for document in validation_docs])\n",
    "predicted = pd.Series([document.predicted for document in validation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual == predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to two parts with equal number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_document(document):\n",
    "    \"\"\"\n",
    "    Splits a document to 2 chunks with equal number of sentences.\n",
    "    Calculates similarities between the two chunks and predicts different author.\n",
    "    Returns True if the predicted value for different author is True.\n",
    "    \"\"\"\n",
    "    number_of_sentences = len(document.sentences)\n",
    "    chunks = [TextChunk(' '.join(document.sentences[:number_of_sentences//2])),\n",
    "              TextChunk(' '.join(document.sentences[number_of_sentences//2:]))]\n",
    "\n",
    "    vectors = map(lambda chunk: VECTORS_SCALER.transform(chunk.to_vector()), chunks)\n",
    "    chunk_similarities = pd.DataFrame(columns=similarity_measures)\n",
    "    \n",
    "    for first_vector, second_vector in combinations(vectors, 2):\n",
    "        chunk_similarities.loc[len(chunk_similarities)] = similarities(first_vector, second_vector)\n",
    "        \n",
    "    chunk_similarities = SIMILARITIES_SCALER.transform(chunk_similarities)\n",
    "    \n",
    "    return any(SVC.predict(chunk_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for document in validation_docs:\n",
    "    document.predicted = classify_document(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = pd.Series([document.has_changes for document in validation_docs])\n",
    "predicted = pd.Series([document.predicted for document in validation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(actual == predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
