{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import train / val as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_features_scaled_standard.csv', index_col=0)\n",
    "val = pd.read_csv('../data/validation_features_scaled_standard.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_features = int((train.shape[1] - 1) / 2)\n",
    "assert number_of_features == 938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_columns = ['A_{}'.format(i) for i in range(number_of_features)]\n",
    "b_columns = ['B_{}'.format(i) for i in range(number_of_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_A = train[a_columns]\n",
    "train_B = train[b_columns]\n",
    "\n",
    "val_A = val[a_columns]\n",
    "val_B = val[b_columns]\n",
    "\n",
    "# rename columns so that both datasets have the same columns\n",
    "train_A.columns = range(number_of_features)\n",
    "train_B.columns = range(number_of_features)\n",
    "\n",
    "val_A.columns = range(number_of_features)\n",
    "val_B.columns = range(number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train datasets - each observation is the absolute difference in A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = abs(train_A - train_B)\n",
    "val_X = abs(val_A - val_B)\n",
    "\n",
    "train_y = train['different_author']\n",
    "val_y = val['different_author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No prunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_estimators:  100\n",
      "train score:  1.0\n",
      "val score:  0.679245283019\n",
      "oob score:  0.719099221131\n",
      "\n",
      "n_estimators:  150\n",
      "train score:  1.0\n",
      "val score:  0.711492281304\n",
      "oob score:  0.739417541483\n",
      "\n",
      "n_estimators:  200\n",
      "train score:  1.0\n",
      "val score:  0.714579759863\n",
      "oob score:  0.750253979004\n",
      "\n",
      "n_estimators:  250\n",
      "train score:  1.0\n",
      "val score:  0.720068610635\n",
      "oob score:  0.764476803251\n",
      "\n",
      "n_estimators:  275\n",
      "train score:  1.0\n",
      "val score:  0.710120068611\n",
      "oob score:  0.758211987809\n"
     ]
    }
   ],
   "source": [
    "for n in [100, 150, 200, 250, 275]:\n",
    "    model = ExtraTreesClassifier(n_estimators=n, n_jobs=-1, oob_score=True, bootstrap=True)\n",
    "    model.fit(train_X, train_y)\n",
    "    print('\\nn_estimators: ', n)\n",
    "    print('train score: ', model.score(train_X, train_y))\n",
    "    print('val score: ', model.score(val_X, val_y))\n",
    "    print('oob score: ', model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_estimators:  100\n",
      "train score:  0.714866237724\n",
      "val score:  0.684391080617\n",
      "oob score:  0.668134100914\n",
      "\n",
      "n_estimators:  150\n",
      "train score:  0.726718591263\n",
      "val score:  0.677186963979\n",
      "oob score:  0.668642058923\n",
      "\n",
      "n_estimators:  200\n",
      "train score:  0.729427700643\n",
      "val score:  0.68576329331\n",
      "oob score:  0.663223840163\n",
      "\n",
      "n_estimators:  250\n",
      "train score:  0.732814087369\n",
      "val score:  0.682675814751\n",
      "oob score:  0.676430748391\n",
      "\n",
      "n_estimators:  275\n",
      "train score:  0.732136810024\n",
      "val score:  0.682675814751\n",
      "oob score:  0.683711479851\n"
     ]
    }
   ],
   "source": [
    "for n in [100, 150, 200, 250, 275]:\n",
    "    model = ExtraTreesClassifier(n_estimators=n, n_jobs=-1, oob_score=True, bootstrap=True, max_depth=3)\n",
    "    model.fit(train_X, train_y)\n",
    "    print('\\nn_estimators: ', n)\n",
    "    print('train score: ', model.score(train_X, train_y))\n",
    "    print('val score: ', model.score(val_X, val_y))\n",
    "    print('oob score: ', model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features/feature_names.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['importance'] = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Spaces</td>\n",
       "      <td>0.026237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Mean paragraph Length</td>\n",
       "      <td>0.012651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lexical diversity</td>\n",
       "      <td>0.005444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Mean Sentence Length</td>\n",
       "      <td>0.004961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ari Index</td>\n",
       "      <td>0.004742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dale Chall Known Fraction</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Gunning Fog Index</td>\n",
       "      <td>0.004378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colons</td>\n",
       "      <td>0.004320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Commas</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Flesch Kincaid Grade</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Special characters</td>\n",
       "      <td>0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Flesch Reading Ease</td>\n",
       "      <td>0.003890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Lix Index</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dale Chall Score</td>\n",
       "      <td>0.003505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Punctuation</td>\n",
       "      <td>0.003379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>UpperCase Letters</td>\n",
       "      <td>0.003285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Even more special characters</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Numbers</td>\n",
       "      <td>0.003210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>some</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Mean syllables per word</td>\n",
       "      <td>0.002797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Smog Index</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>my</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>so</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coleman Liau Index</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Hyphens</td>\n",
       "      <td>0.002518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Words with &gt;= 3 syllables</td>\n",
       "      <td>0.002467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>which</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>ding</td>\n",
       "      <td>0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DT_NN_VBZ</td>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Mean Word Length</td>\n",
       "      <td>0.002356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>doesn</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>ve</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>ours</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>isn</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>ll</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>yourselves</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>wasn</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>ma</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>didn</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>hers</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>haven</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>couldn</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>mustn't</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>weren</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>needn't</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>mightn't</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Quotations</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>needn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>shan't</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>aren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>mustn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>shouldn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>wouldn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>that'll</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>hadn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>should've</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>mightn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>shan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>hasn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>938 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "203                        Spaces    0.026237\n",
       "123         Mean paragraph Length    0.012651\n",
       "112             Lexical diversity    0.005444\n",
       "121          Mean Sentence Length    0.004961\n",
       "1                       Ari Index    0.004742\n",
       "46      Dale Chall Known Fraction    0.004519\n",
       "56              Gunning Fog Index    0.004378\n",
       "6                          Colons    0.004320\n",
       "7                          Commas    0.004218\n",
       "53           Flesch Kincaid Grade    0.004066\n",
       "204            Special characters    0.004033\n",
       "54            Flesch Reading Ease    0.003890\n",
       "113                     Lix Index    0.003703\n",
       "47               Dale Chall Score    0.003505\n",
       "187                   Punctuation    0.003379\n",
       "215             UpperCase Letters    0.003285\n",
       "50   Even more special characters    0.003220\n",
       "175                       Numbers    0.003210\n",
       "787                          some    0.002853\n",
       "124       Mean syllables per word    0.002797\n",
       "202                    Smog Index    0.002765\n",
       "611                            my    0.002676\n",
       "786                            so    0.002634\n",
       "5              Coleman Liau Index    0.002631\n",
       "59                        Hyphens    0.002518\n",
       "244     Words with >= 3 syllables    0.002467\n",
       "905                         which    0.002383\n",
       "382                          ding    0.002365\n",
       "42                      DT_NN_VBZ    0.002362\n",
       "122              Mean Word Length    0.002356\n",
       "..                            ...         ...\n",
       "387                         doesn    0.000031\n",
       "883                            ve    0.000023\n",
       "681                          ours    0.000022\n",
       "541                           isn    0.000021\n",
       "577                            ll    0.000020\n",
       "936                    yourselves    0.000019\n",
       "893                          wasn    0.000017\n",
       "586                            ma    0.000015\n",
       "379                          didn    0.000011\n",
       "488                          hers    0.000011\n",
       "480                         haven    0.000010\n",
       "363                        couldn    0.000005\n",
       "610                       mustn't    0.000004\n",
       "899                         weren    0.000002\n",
       "621                       needn't    0.000002\n",
       "599                      mightn't    0.000000\n",
       "189                    Quotations    0.000000\n",
       "620                         needn    0.000000\n",
       "768                        shan't    0.000000\n",
       "296                          aren    0.000000\n",
       "609                         mustn    0.000000\n",
       "773                       shouldn    0.000000\n",
       "919                        wouldn    0.000000\n",
       "272                           ain    0.000000\n",
       "830                       that'll    0.000000\n",
       "471                          hadn    0.000000\n",
       "772                     should've    0.000000\n",
       "598                        mightn    0.000000\n",
       "767                          shan    0.000000\n",
       "477                          hasn    0.000000\n",
       "\n",
       "[938 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
