{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import train / val as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_features_scaled_standard.csv', index_col=0)\n",
    "val = pd.read_csv('../data/validation_features_scaled_standard.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_features = int((train.shape[1] - 1) / 2)\n",
    "assert number_of_features == 938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import features index to name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features/feature_names.csv', index_col=0)\n",
    "\n",
    "assert features.shape[0] == 938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_columns = ['A_{}'.format(i) for i in range(number_of_features)]\n",
    "b_columns = ['B_{}'.format(i) for i in range(number_of_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_A = train[a_columns]\n",
    "train_B = train[b_columns]\n",
    "\n",
    "val_A = val[a_columns]\n",
    "val_B = val[b_columns]\n",
    "\n",
    "# rename columns so that both datasets have the same columns\n",
    "train_A.columns = range(number_of_features)\n",
    "train_B.columns = range(number_of_features)\n",
    "\n",
    "val_A.columns = range(number_of_features)\n",
    "val_B.columns = range(number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train datasets - each observation is the absolute difference in A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = abs(train_A - train_B)\n",
    "val_X = abs(val_A - val_B)\n",
    "\n",
    "train_y = train['different_author']\n",
    "val_y = val['different_author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No prunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_estimators:  150\n",
      "train score:  1.0\n",
      "val score:  0.720411663808\n",
      "oob score:  0.738232306129\n"
     ]
    }
   ],
   "source": [
    "# for n in [50, 100, 150, 200, 250, 275]:\n",
    "n=150\n",
    "model = RandomForestClassifier(n_estimators=n, n_jobs=-1, oob_score=True, bootstrap=True)\n",
    "model.fit(train_X, train_y)\n",
    "print('\\nn_estimators: ', n)\n",
    "print('train score: ', model.score(train_X, train_y))\n",
    "print('val score: ', model.score(val_X, val_y))\n",
    "print('oob score: ', model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Mean paragraph Length</td>\n",
       "      <td>0.012921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lexical diversity</td>\n",
       "      <td>0.005720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dale Chall Known Fraction</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dale Chall Score</td>\n",
       "      <td>0.004421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Commas</td>\n",
       "      <td>0.004387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Special characters</td>\n",
       "      <td>0.004142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colons</td>\n",
       "      <td>0.003914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Lix Index</td>\n",
       "      <td>0.003844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Flesch Kincaid Grade</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Even more special characters</td>\n",
       "      <td>0.003652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Flesch Reading Ease</td>\n",
       "      <td>0.003651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ari Index</td>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>UpperCase Letters</td>\n",
       "      <td>0.003527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Mean Sentence Length</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Gunning Fog Index</td>\n",
       "      <td>0.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Numbers</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Mean syllables per word</td>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Smog Index</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Punctuation</td>\n",
       "      <td>0.002824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>other</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DT_NN_NN</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Hyphens</td>\n",
       "      <td>0.002544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>H</td>\n",
       "      <td>0.002535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>which</td>\n",
       "      <td>0.002535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>but</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Mean Word Length</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>some</td>\n",
       "      <td>0.002514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>be</td>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>IN_NN___END__</td>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NN_NN_IN</td>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>yourselves</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>wasn</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>don</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>didn</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>ll</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>hadn't</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>isn</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>that'll</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>ma</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>should've</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>wouldn</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>haven</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>hers</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>needn't</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>mustn't</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>ve</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>couldn</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>shan't</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>needn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>shan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>hadn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>shouldn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>weren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>hasn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>mightn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>mightn't</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Quotations</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>mustn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>aren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>938 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature     model\n",
       "123         Mean paragraph Length  0.012921\n",
       "112             Lexical diversity  0.005720\n",
       "46      Dale Chall Known Fraction  0.005501\n",
       "47               Dale Chall Score  0.004421\n",
       "7                          Commas  0.004387\n",
       "204            Special characters  0.004142\n",
       "6                          Colons  0.003914\n",
       "113                     Lix Index  0.003844\n",
       "53           Flesch Kincaid Grade  0.003830\n",
       "50   Even more special characters  0.003652\n",
       "54            Flesch Reading Ease  0.003651\n",
       "1                       Ari Index  0.003569\n",
       "215             UpperCase Letters  0.003527\n",
       "121          Mean Sentence Length  0.003389\n",
       "56              Gunning Fog Index  0.003103\n",
       "175                       Numbers  0.003069\n",
       "124       Mean syllables per word  0.003027\n",
       "202                    Smog Index  0.002853\n",
       "187                   Punctuation  0.002824\n",
       "675                         other  0.002813\n",
       "35                       DT_NN_NN  0.002553\n",
       "59                        Hyphens  0.002544\n",
       "57                              H  0.002535\n",
       "905                         which  0.002535\n",
       "333                           but  0.002532\n",
       "122              Mean Word Length  0.002516\n",
       "787                          some  0.002514\n",
       "320                            be  0.002498\n",
       "86                  IN_NN___END__  0.002487\n",
       "162                      NN_NN_IN  0.002485\n",
       "..                            ...       ...\n",
       "936                    yourselves  0.000034\n",
       "893                          wasn  0.000030\n",
       "390                           don  0.000029\n",
       "379                          didn  0.000020\n",
       "577                            ll  0.000017\n",
       "472                        hadn't  0.000017\n",
       "541                           isn  0.000016\n",
       "830                       that'll  0.000016\n",
       "586                            ma  0.000012\n",
       "772                     should've  0.000011\n",
       "919                        wouldn  0.000009\n",
       "480                         haven  0.000009\n",
       "488                          hers  0.000008\n",
       "621                       needn't  0.000004\n",
       "610                       mustn't  0.000004\n",
       "883                            ve  0.000004\n",
       "363                        couldn  0.000004\n",
       "768                        shan't  0.000000\n",
       "620                         needn  0.000000\n",
       "767                          shan  0.000000\n",
       "471                          hadn  0.000000\n",
       "272                           ain  0.000000\n",
       "773                       shouldn  0.000000\n",
       "899                         weren  0.000000\n",
       "477                          hasn  0.000000\n",
       "598                        mightn  0.000000\n",
       "599                      mightn't  0.000000\n",
       "189                    Quotations  0.000000\n",
       "609                         mustn  0.000000\n",
       "296                          aren  0.000000\n",
       "\n",
       "[938 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['model'] = model.feature_importances_\n",
    "features.sort_values('model', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With prunning based on:\n",
    "    - min leaf samples\n",
    "    - max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "depth:  2\n",
      "train score:  0.722146969184\n",
      "val score:  0.682332761578\n",
      "oob score:  0.678123941754\n",
      "\n",
      "depth:  3\n",
      "train score:  0.757534710464\n",
      "val score:  0.68576329331\n",
      "oob score:  0.692516085337\n",
      "\n",
      "depth:  4\n",
      "train score:  0.793430409753\n",
      "val score:  0.700857632933\n",
      "oob score:  0.708770741619\n",
      "\n",
      "depth:  5\n",
      "train score:  0.843379613952\n",
      "val score:  0.703945111492\n",
      "oob score:  0.718083305113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-215414054230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\ndepth: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_oob_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Decapsulate classes_ attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_set_oob_score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    426\u001b[0m             unsampled_indices = _generate_unsampled_indices(\n\u001b[1;32m    427\u001b[0m                 estimator.random_state, n_samples)\n\u001b[0;32m--> 428\u001b[0;31m             p_estimator = estimator.predict_proba(X[unsampled_indices, :],\n\u001b[0m\u001b[1;32m    429\u001b[0m                                                   check_input=False)\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for depth in [2, 3, 4, 5, 6, 7]:\n",
    "    model = RandomForestClassifier(n_estimators=200, n_jobs=-1, oob_score=True, bootstrap=True, max_depth=depth)\n",
    "    model.fit(train_X, train_y)\n",
    "    print('\\ndepth: ', depth)\n",
    "    print('train score: ', model.score(train_X, train_y))\n",
    "    print('val score: ', model.score(val_X, val_y))\n",
    "    print('oob score: ', model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "min_leaf_samples:  100\n",
      "train score:  0.771249576702\n",
      "val score:  0.696397941681\n",
      "oob score:  0.692346766001\n",
      "\n",
      "min_leaf_samples:  125\n",
      "train score:  0.768201828649\n",
      "val score:  0.695025728988\n",
      "oob score:  0.695225194717\n",
      "\n",
      "min_leaf_samples:  150\n",
      "train score:  0.760751777853\n",
      "val score:  0.70154373928\n",
      "oob score:  0.691500169319\n",
      "\n",
      "min_leaf_samples:  170\n",
      "train score:  0.751608533695\n",
      "val score:  0.690222984563\n",
      "oob score:  0.685235353877\n",
      "\n",
      "min_leaf_samples:  175\n",
      "train score:  0.761598374534\n",
      "val score:  0.70051457976\n",
      "oob score:  0.688621740603\n",
      "\n",
      "min_leaf_samples:  200\n",
      "train score:  0.752455130376\n",
      "val score:  0.693996569468\n",
      "oob score:  0.687436505249\n",
      "\n",
      "min_leaf_samples:  225\n",
      "train score:  0.747544869624\n",
      "val score:  0.689536878216\n",
      "oob score:  0.680663731798\n",
      "\n",
      "min_leaf_samples:  250\n",
      "train score:  0.741110734846\n",
      "val score:  0.68782161235\n",
      "oob score:  0.684727395869\n",
      "\n",
      "min_leaf_samples:  275\n",
      "train score:  0.744497121571\n",
      "val score:  0.695711835334\n",
      "oob score:  0.678631899763\n",
      "\n",
      "min_leaf_samples:  300\n",
      "train score:  0.738062986793\n",
      "val score:  0.689193825043\n",
      "oob score:  0.686589908568\n"
     ]
    }
   ],
   "source": [
    "for samples in [100, 125, 150, 170, 175, 200, 225, 250, 275, 300]:\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, bootstrap=True,\n",
    "                                   max_depth=4, min_samples_leaf=samples)\n",
    "    model.fit(train_X, train_y)\n",
    "    print('\\nmin_leaf_samples: ', samples)\n",
    "    print('train score: ', model.score(train_X, train_y))\n",
    "    print('val score: ', model.score(val_X, val_y))\n",
    "    print('oob score: ', model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max depth:  4\n",
      "\n",
      "min_leaf_samples:  150\n",
      "train score:  0.74365052489\n",
      "val score:  0.695025728988\n",
      "oob score:  0.686420589231\n"
     ]
    }
   ],
   "source": [
    "model_prunned = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, bootstrap=True,\n",
    "                               max_depth=4, min_samples_leaf=275)\n",
    "model_prunned.fit(train_X, train_y)\n",
    "print('\\nmax depth: ', 4)\n",
    "print('\\nmin_leaf_samples: ', 150)\n",
    "print('train score: ', model_prunned.score(train_X, train_y))\n",
    "print('val score: ', model_prunned.score(val_X, val_y))\n",
    "print('oob score: ', model_prunned.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ari Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC_DT_NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature\n",
       "0          A\n",
       "1  Ari Index\n",
       "2          B\n",
       "3          C\n",
       "4   CC_DT_NN"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['importance'] = model_prunned.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_prunned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Mean paragraph Length</td>\n",
       "      <td>0.051432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lexical diversity</td>\n",
       "      <td>0.036576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>some</td>\n",
       "      <td>0.027229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dale Chall Known Fraction</td>\n",
       "      <td>0.022091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>other</td>\n",
       "      <td>0.021045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  importance_prunned\n",
       "123      Mean paragraph Length            0.051432\n",
       "112          Lexical diversity            0.036576\n",
       "787                       some            0.027229\n",
       "46   Dale Chall Known Fraction            0.022091\n",
       "675                      other            0.021045"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = features[['feature', 'importance']].sort_values('importance', ascending=False)\n",
    "features.to_csv('../data/features/prunne')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['rank'] = features['model'].rank(ascending=False)\n",
    "features['rank_prunned'] = features['model_prunned'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['model'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_values('model', ascending=False).to_csv('bla.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.sort_values('model_prunned', ascending=False).to_csv('bla_prunned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = model_prunned.feature_importances_.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n:  5\n",
      "train score:  0.66288520149\n",
      "val score:  0.595197255575\n",
      "\n",
      "n:  10\n",
      "train score:  0.706400270911\n",
      "val score:  0.628816466552\n",
      "\n",
      "n:  20\n",
      "train score:  0.736539112767\n",
      "val score:  0.669982847341\n",
      "\n",
      "n:  25\n",
      "train score:  0.753979004402\n",
      "val score:  0.669296740995\n",
      "\n",
      "n:  30\n",
      "train score:  0.761429055198\n",
      "val score:  0.685420240137\n",
      "\n",
      "n:  35\n",
      "train score:  0.77175753471\n",
      "val score:  0.683018867925\n",
      "\n",
      "n:  40\n",
      "train score:  0.775313240772\n",
      "val score:  0.68782161235\n",
      "\n",
      "n:  50\n",
      "train score:  0.791398577718\n",
      "val score:  0.684391080617\n",
      "\n",
      "n:  70\n",
      "train score:  0.808669150017\n",
      "val score:  0.695711835334\n",
      "\n",
      "n:  90\n",
      "train score:  0.812394175415\n",
      "val score:  0.69845626072\n",
      "\n",
      "n:  100\n",
      "train score:  0.825431764307\n",
      "val score:  0.709090909091\n"
     ]
    }
   ],
   "source": [
    "for n in [5,10,20, 25, 30,35, 40, 50, 70, 90, 100]:\n",
    "    model = RandomForestClassifier(n_estimators=n, n_jobs=-1, min_samples_leaf=50)\n",
    "    model.fit(train_X[sorted_[:n]], train_y)\n",
    "    print('\\nn: ', n)\n",
    "    print('train score: ', model.score(train_X[sorted_[:n]], train_y))\n",
    "    print('val score: ', model.score(val_X[sorted_[:n]], val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [50, 75, 100], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [3, 4, 5, 6], 'criterion': ['entropy', 'gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, bootstrap=True, oob_score=True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87588892651540806"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71526586620926247"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472406</td>\n",
       "      <td>0.108852</td>\n",
       "      <td>0.672367</td>\n",
       "      <td>0.754149</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.745397</td>\n",
       "      <td>0.651143</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.006891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.711917</td>\n",
       "      <td>0.109194</td>\n",
       "      <td>0.681510</td>\n",
       "      <td>0.758127</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.750476</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.756825</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.771217</td>\n",
       "      <td>0.049149</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.007984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983586</td>\n",
       "      <td>0.109236</td>\n",
       "      <td>0.665256</td>\n",
       "      <td>0.758508</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655377</td>\n",
       "      <td>0.754074</td>\n",
       "      <td>0.654530</td>\n",
       "      <td>0.764021</td>\n",
       "      <td>0.674852</td>\n",
       "      <td>0.753439</td>\n",
       "      <td>0.055501</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.007916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540163</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.673552</td>\n",
       "      <td>0.758127</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660457</td>\n",
       "      <td>0.744974</td>\n",
       "      <td>0.670618</td>\n",
       "      <td>0.768677</td>\n",
       "      <td>0.689246</td>\n",
       "      <td>0.754074</td>\n",
       "      <td>0.079387</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708900</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>0.686759</td>\n",
       "      <td>0.757196</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.670618</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.701101</td>\n",
       "      <td>0.758942</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.007722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.978851</td>\n",
       "      <td>0.109036</td>\n",
       "      <td>0.677955</td>\n",
       "      <td>0.761768</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670618</td>\n",
       "      <td>0.757672</td>\n",
       "      <td>0.661304</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.703641</td>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.086849</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.005995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.378157</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.656620</td>\n",
       "      <td>0.743438</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662151</td>\n",
       "      <td>0.744127</td>\n",
       "      <td>0.638442</td>\n",
       "      <td>0.759788</td>\n",
       "      <td>0.674005</td>\n",
       "      <td>0.745397</td>\n",
       "      <td>0.041386</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.010922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.590269</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>0.662547</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660457</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.653683</td>\n",
       "      <td>0.754497</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.750265</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.006970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.729171</td>\n",
       "      <td>0.109402</td>\n",
       "      <td>0.662547</td>\n",
       "      <td>0.751651</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.740952</td>\n",
       "      <td>0.652837</td>\n",
       "      <td>0.757884</td>\n",
       "      <td>0.667231</td>\n",
       "      <td>0.744974</td>\n",
       "      <td>0.045068</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.016869</td>\n",
       "      <td>0.010317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.575485</td>\n",
       "      <td>0.109377</td>\n",
       "      <td>0.680494</td>\n",
       "      <td>0.788097</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693480</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.673158</td>\n",
       "      <td>0.779259</td>\n",
       "      <td>0.682472</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.033159</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.005349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.797700</td>\n",
       "      <td>0.107742</td>\n",
       "      <td>0.690654</td>\n",
       "      <td>0.801092</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691787</td>\n",
       "      <td>0.811005</td>\n",
       "      <td>0.663844</td>\n",
       "      <td>0.799577</td>\n",
       "      <td>0.705334</td>\n",
       "      <td>0.790053</td>\n",
       "      <td>0.039329</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.069208</td>\n",
       "      <td>0.108940</td>\n",
       "      <td>0.682696</td>\n",
       "      <td>0.797197</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703641</td>\n",
       "      <td>0.797672</td>\n",
       "      <td>0.661304</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.697714</td>\n",
       "      <td>0.791323</td>\n",
       "      <td>0.090866</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.006033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.581243</td>\n",
       "      <td>0.108917</td>\n",
       "      <td>0.677277</td>\n",
       "      <td>0.791610</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>0.799153</td>\n",
       "      <td>0.669771</td>\n",
       "      <td>0.797672</td>\n",
       "      <td>0.691787</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.026727</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.109954</td>\n",
       "      <td>0.686759</td>\n",
       "      <td>0.800330</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685013</td>\n",
       "      <td>0.798730</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.795132</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.807196</td>\n",
       "      <td>0.045994</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.005864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.054389</td>\n",
       "      <td>0.109461</td>\n",
       "      <td>0.685405</td>\n",
       "      <td>0.797621</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683319</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.674852</td>\n",
       "      <td>0.800212</td>\n",
       "      <td>0.693480</td>\n",
       "      <td>0.801905</td>\n",
       "      <td>0.049031</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.005689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.429391</td>\n",
       "      <td>0.108614</td>\n",
       "      <td>0.660007</td>\n",
       "      <td>0.775440</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651990</td>\n",
       "      <td>0.765503</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.775661</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.006587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.593323</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.667457</td>\n",
       "      <td>0.783356</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668078</td>\n",
       "      <td>0.783915</td>\n",
       "      <td>0.647756</td>\n",
       "      <td>0.790053</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.776508</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.006616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.716841</td>\n",
       "      <td>0.108061</td>\n",
       "      <td>0.669489</td>\n",
       "      <td>0.790255</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.789630</td>\n",
       "      <td>0.644369</td>\n",
       "      <td>0.791534</td>\n",
       "      <td>0.699407</td>\n",
       "      <td>0.790053</td>\n",
       "      <td>0.056119</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.018607</td>\n",
       "      <td>0.005011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.106436</td>\n",
       "      <td>0.693363</td>\n",
       "      <td>0.837877</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687553</td>\n",
       "      <td>0.831534</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.840423</td>\n",
       "      <td>0.710415</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.012078</td>\n",
       "      <td>0.004586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.898683</td>\n",
       "      <td>0.106882</td>\n",
       "      <td>0.695225</td>\n",
       "      <td>0.841644</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.854180</td>\n",
       "      <td>0.674005</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.713802</td>\n",
       "      <td>0.839153</td>\n",
       "      <td>0.034958</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>0.006416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.224333</td>\n",
       "      <td>0.107334</td>\n",
       "      <td>0.691331</td>\n",
       "      <td>0.849136</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.846138</td>\n",
       "      <td>0.685859</td>\n",
       "      <td>0.852063</td>\n",
       "      <td>0.699407</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.056577</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.680849</td>\n",
       "      <td>0.107201</td>\n",
       "      <td>0.688622</td>\n",
       "      <td>0.832586</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685013</td>\n",
       "      <td>0.832169</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.833439</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.922926</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>0.695733</td>\n",
       "      <td>0.844353</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.679932</td>\n",
       "      <td>0.842751</td>\n",
       "      <td>0.723963</td>\n",
       "      <td>0.837249</td>\n",
       "      <td>0.066653</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.008379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.233862</td>\n",
       "      <td>0.108869</td>\n",
       "      <td>0.691331</td>\n",
       "      <td>0.847867</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694327</td>\n",
       "      <td>0.848254</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.851217</td>\n",
       "      <td>0.705334</td>\n",
       "      <td>0.842751</td>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.003459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.484592</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.668473</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679086</td>\n",
       "      <td>0.819471</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.817354</td>\n",
       "      <td>0.674005</td>\n",
       "      <td>0.821376</td>\n",
       "      <td>0.035995</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.005076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.596310</td>\n",
       "      <td>0.108679</td>\n",
       "      <td>0.674230</td>\n",
       "      <td>0.829495</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685013</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.651990</td>\n",
       "      <td>0.832804</td>\n",
       "      <td>0.690093</td>\n",
       "      <td>0.827090</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.810835</td>\n",
       "      <td>0.107347</td>\n",
       "      <td>0.678632</td>\n",
       "      <td>0.836141</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687553</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.838942</td>\n",
       "      <td>0.679086</td>\n",
       "      <td>0.830899</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.676725</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>0.694379</td>\n",
       "      <td>0.886386</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697714</td>\n",
       "      <td>0.885291</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.892275</td>\n",
       "      <td>0.691787</td>\n",
       "      <td>0.887407</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.004551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.001135</td>\n",
       "      <td>0.107954</td>\n",
       "      <td>0.701998</td>\n",
       "      <td>0.891085</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715495</td>\n",
       "      <td>0.890582</td>\n",
       "      <td>0.685859</td>\n",
       "      <td>0.890582</td>\n",
       "      <td>0.716342</td>\n",
       "      <td>0.892698</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.323011</td>\n",
       "      <td>0.108805</td>\n",
       "      <td>0.699120</td>\n",
       "      <td>0.892101</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703641</td>\n",
       "      <td>0.896720</td>\n",
       "      <td>0.679086</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.707875</td>\n",
       "      <td>0.883810</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.366372</td>\n",
       "      <td>0.108528</td>\n",
       "      <td>0.658652</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'max_fea...</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657070</td>\n",
       "      <td>0.750476</td>\n",
       "      <td>0.640982</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.518746</td>\n",
       "      <td>0.109428</td>\n",
       "      <td>0.662716</td>\n",
       "      <td>0.745724</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'max_fea...</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.749841</td>\n",
       "      <td>0.623201</td>\n",
       "      <td>0.739048</td>\n",
       "      <td>0.679086</td>\n",
       "      <td>0.752169</td>\n",
       "      <td>0.081506</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.024137</td>\n",
       "      <td>0.005148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.696699</td>\n",
       "      <td>0.110120</td>\n",
       "      <td>0.667288</td>\n",
       "      <td>0.751482</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'max_fea...</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>0.749206</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.751958</td>\n",
       "      <td>0.050647</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.003412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.472354</td>\n",
       "      <td>0.108204</td>\n",
       "      <td>0.682865</td>\n",
       "      <td>0.788308</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685859</td>\n",
       "      <td>0.787937</td>\n",
       "      <td>0.666384</td>\n",
       "      <td>0.782434</td>\n",
       "      <td>0.700254</td>\n",
       "      <td>0.800423</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.007862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.685568</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>0.683881</td>\n",
       "      <td>0.796690</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.799153</td>\n",
       "      <td>0.654530</td>\n",
       "      <td>0.800635</td>\n",
       "      <td>0.705334</td>\n",
       "      <td>0.794921</td>\n",
       "      <td>0.034933</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.016768</td>\n",
       "      <td>0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.907427</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.695395</td>\n",
       "      <td>0.798891</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693480</td>\n",
       "      <td>0.792169</td>\n",
       "      <td>0.680779</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>0.709568</td>\n",
       "      <td>0.798730</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.006627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.472332</td>\n",
       "      <td>0.109969</td>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.786784</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.790899</td>\n",
       "      <td>0.677392</td>\n",
       "      <td>0.786032</td>\n",
       "      <td>0.690093</td>\n",
       "      <td>0.780529</td>\n",
       "      <td>0.027722</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.004890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.688232</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.693532</td>\n",
       "      <td>0.795589</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705334</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.792169</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>0.800423</td>\n",
       "      <td>0.036544</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.005425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.903119</td>\n",
       "      <td>0.110252</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.801346</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697714</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.804656</td>\n",
       "      <td>0.707028</td>\n",
       "      <td>0.811217</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.007113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.369084</td>\n",
       "      <td>0.110322</td>\n",
       "      <td>0.657636</td>\n",
       "      <td>0.779546</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658764</td>\n",
       "      <td>0.787513</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.784339</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>0.007815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.583991</td>\n",
       "      <td>0.109438</td>\n",
       "      <td>0.665256</td>\n",
       "      <td>0.787842</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.790053</td>\n",
       "      <td>0.647756</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>0.794709</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.005364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.109565</td>\n",
       "      <td>0.672706</td>\n",
       "      <td>0.789282</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.790688</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.794497</td>\n",
       "      <td>0.680779</td>\n",
       "      <td>0.792169</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.574360</td>\n",
       "      <td>0.109398</td>\n",
       "      <td>0.691162</td>\n",
       "      <td>0.834321</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713802</td>\n",
       "      <td>0.830476</td>\n",
       "      <td>0.662151</td>\n",
       "      <td>0.838307</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.834497</td>\n",
       "      <td>0.023232</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0.003707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.792668</td>\n",
       "      <td>0.109763</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.846427</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685013</td>\n",
       "      <td>0.844656</td>\n",
       "      <td>0.673158</td>\n",
       "      <td>0.844656</td>\n",
       "      <td>0.696020</td>\n",
       "      <td>0.843598</td>\n",
       "      <td>0.036018</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.012222</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.851337</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700254</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.853757</td>\n",
       "      <td>0.713802</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.003305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.574967</td>\n",
       "      <td>0.108743</td>\n",
       "      <td>0.694717</td>\n",
       "      <td>0.836607</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703641</td>\n",
       "      <td>0.840212</td>\n",
       "      <td>0.685859</td>\n",
       "      <td>0.841058</td>\n",
       "      <td>0.699407</td>\n",
       "      <td>0.829841</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.794340</td>\n",
       "      <td>0.108221</td>\n",
       "      <td>0.696241</td>\n",
       "      <td>0.843337</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691787</td>\n",
       "      <td>0.842963</td>\n",
       "      <td>0.684166</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.701948</td>\n",
       "      <td>0.838730</td>\n",
       "      <td>0.038932</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.041563</td>\n",
       "      <td>0.106843</td>\n",
       "      <td>0.691331</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701948</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.843175</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>0.842751</td>\n",
       "      <td>0.049603</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.004575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.373622</td>\n",
       "      <td>0.108494</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.823738</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.826243</td>\n",
       "      <td>0.635902</td>\n",
       "      <td>0.830053</td>\n",
       "      <td>0.673158</td>\n",
       "      <td>0.825608</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.004668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.587808</td>\n",
       "      <td>0.109864</td>\n",
       "      <td>0.679478</td>\n",
       "      <td>0.835464</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.663844</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.696020</td>\n",
       "      <td>0.833228</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.699907</td>\n",
       "      <td>0.108591</td>\n",
       "      <td>0.671520</td>\n",
       "      <td>0.841644</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674005</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.660457</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>0.684166</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.047034</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.573475</td>\n",
       "      <td>0.109523</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0.893540</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687553</td>\n",
       "      <td>0.905608</td>\n",
       "      <td>0.702794</td>\n",
       "      <td>0.894180</td>\n",
       "      <td>0.689246</td>\n",
       "      <td>0.896720</td>\n",
       "      <td>0.025570</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.007538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.793444</td>\n",
       "      <td>0.109527</td>\n",
       "      <td>0.696410</td>\n",
       "      <td>0.897435</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.898413</td>\n",
       "      <td>0.680779</td>\n",
       "      <td>0.898413</td>\n",
       "      <td>0.712955</td>\n",
       "      <td>0.898201</td>\n",
       "      <td>0.032769</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.003904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.115224</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.700135</td>\n",
       "      <td>0.897223</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693480</td>\n",
       "      <td>0.893757</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.903492</td>\n",
       "      <td>0.707028</td>\n",
       "      <td>0.894603</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.004965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.574711</td>\n",
       "      <td>0.108004</td>\n",
       "      <td>0.694379</td>\n",
       "      <td>0.887953</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.882751</td>\n",
       "      <td>0.674005</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.702794</td>\n",
       "      <td>0.890370</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.791349</td>\n",
       "      <td>0.109092</td>\n",
       "      <td>0.699627</td>\n",
       "      <td>0.898408</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699407</td>\n",
       "      <td>0.906032</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.900741</td>\n",
       "      <td>0.710415</td>\n",
       "      <td>0.901587</td>\n",
       "      <td>0.037159</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.005680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.114544</td>\n",
       "      <td>0.109295</td>\n",
       "      <td>0.701829</td>\n",
       "      <td>0.903192</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709568</td>\n",
       "      <td>0.903492</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.897989</td>\n",
       "      <td>0.709568</td>\n",
       "      <td>0.905608</td>\n",
       "      <td>0.052279</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.385704</td>\n",
       "      <td>0.109781</td>\n",
       "      <td>0.666780</td>\n",
       "      <td>0.876016</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646063</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>0.652837</td>\n",
       "      <td>0.877249</td>\n",
       "      <td>0.680779</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.048699</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>0.002788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.587563</td>\n",
       "      <td>0.109431</td>\n",
       "      <td>0.675246</td>\n",
       "      <td>0.888037</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>0.888042</td>\n",
       "      <td>0.651143</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.701948</td>\n",
       "      <td>0.893968</td>\n",
       "      <td>0.034170</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>0.005983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.110351</td>\n",
       "      <td>0.677277</td>\n",
       "      <td>0.894726</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.890582</td>\n",
       "      <td>0.660457</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.047795</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.472406         0.108852         0.672367          0.754149   \n",
       "1        0.711917         0.109194         0.681510          0.758127   \n",
       "2        0.983586         0.109236         0.665256          0.758508   \n",
       "3        0.540163         0.107169         0.673552          0.758127   \n",
       "4        0.708900         0.107333         0.686759          0.757196   \n",
       "5        0.978851         0.109036         0.677955          0.761768   \n",
       "6        0.378157         0.108821         0.656620          0.743438   \n",
       "7        0.590269         0.107226         0.662547          0.748899   \n",
       "8        0.729171         0.109402         0.662547          0.751651   \n",
       "9        0.575485         0.109377         0.680494          0.788097   \n",
       "10       0.797700         0.107742         0.690654          0.801092   \n",
       "11       1.069208         0.108940         0.682696          0.797197   \n",
       "12       0.581243         0.108917         0.677277          0.791610   \n",
       "13       0.794282         0.109954         0.686759          0.800330   \n",
       "14       1.054389         0.109461         0.685405          0.797621   \n",
       "15       0.429391         0.108614         0.660007          0.775440   \n",
       "16       0.593323         0.108761         0.667457          0.783356   \n",
       "17       0.716841         0.108061         0.669489          0.790255   \n",
       "18       0.675758         0.106436         0.693363          0.837877   \n",
       "19       0.898683         0.106882         0.695225          0.841644   \n",
       "20       1.224333         0.107334         0.691331          0.849136   \n",
       "21       0.680849         0.107201         0.688622          0.832586   \n",
       "22       0.922926         0.108193         0.695733          0.844353   \n",
       "23       1.233862         0.108869         0.691331          0.847867   \n",
       "24       0.484592         0.108613         0.668473          0.823400   \n",
       "25       0.596310         0.108679         0.674230          0.829495   \n",
       "26       0.810835         0.107347         0.678632          0.836141   \n",
       "27       0.676725         0.109631         0.694379          0.886386   \n",
       "28       1.001135         0.107954         0.701998          0.891085   \n",
       "29       1.323011         0.108805         0.699120          0.892101   \n",
       "..            ...              ...              ...               ...   \n",
       "42       0.366372         0.108528         0.658652          0.743100   \n",
       "43       0.518746         0.109428         0.662716          0.745724   \n",
       "44       0.696699         0.110120         0.667288          0.751482   \n",
       "45       0.472354         0.108204         0.682865          0.788308   \n",
       "46       0.685568         0.109260         0.683881          0.796690   \n",
       "47       0.907427         0.109221         0.695395          0.798891   \n",
       "48       0.472332         0.109969         0.688960          0.786784   \n",
       "49       0.688232         0.109119         0.693532          0.795589   \n",
       "50       0.903119         0.110252         0.691500          0.801346   \n",
       "51       0.369084         0.110322         0.657636          0.779546   \n",
       "52       0.583991         0.109438         0.665256          0.787842   \n",
       "53       0.699282         0.109565         0.672706          0.789282   \n",
       "54       0.574360         0.109398         0.691162          0.834321   \n",
       "55       0.792668         0.109763         0.690315          0.846427   \n",
       "56       1.012222         0.108658         0.699966          0.851337   \n",
       "57       0.574967         0.108743         0.694717          0.836607   \n",
       "58       0.794340         0.108221         0.696241          0.843337   \n",
       "59       1.041563         0.106843         0.691331          0.847909   \n",
       "60       0.373622         0.108494         0.661700          0.823738   \n",
       "61       0.587808         0.109864         0.679478          0.835464   \n",
       "62       0.699907         0.108591         0.671520          0.841644   \n",
       "63       0.573475         0.109523         0.697934          0.893540   \n",
       "64       0.793444         0.109527         0.696410          0.897435   \n",
       "65       1.115224         0.109728         0.700135          0.897223   \n",
       "66       0.574711         0.108004         0.694379          0.887953   \n",
       "67       0.791349         0.109092         0.699627          0.898408   \n",
       "68       1.114544         0.109295         0.701829          0.903192   \n",
       "69       0.385704         0.109781         0.666780          0.876016   \n",
       "70       0.587563         0.109431         0.675246          0.888037   \n",
       "71       0.705694         0.110351         0.677277          0.894726   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "0          entropy               3               auto                 50   \n",
       "1          entropy               3               auto                 75   \n",
       "2          entropy               3               auto                100   \n",
       "3          entropy               3               sqrt                 50   \n",
       "4          entropy               3               sqrt                 75   \n",
       "5          entropy               3               sqrt                100   \n",
       "6          entropy               3               log2                 50   \n",
       "7          entropy               3               log2                 75   \n",
       "8          entropy               3               log2                100   \n",
       "9          entropy               4               auto                 50   \n",
       "10         entropy               4               auto                 75   \n",
       "11         entropy               4               auto                100   \n",
       "12         entropy               4               sqrt                 50   \n",
       "13         entropy               4               sqrt                 75   \n",
       "14         entropy               4               sqrt                100   \n",
       "15         entropy               4               log2                 50   \n",
       "16         entropy               4               log2                 75   \n",
       "17         entropy               4               log2                100   \n",
       "18         entropy               5               auto                 50   \n",
       "19         entropy               5               auto                 75   \n",
       "20         entropy               5               auto                100   \n",
       "21         entropy               5               sqrt                 50   \n",
       "22         entropy               5               sqrt                 75   \n",
       "23         entropy               5               sqrt                100   \n",
       "24         entropy               5               log2                 50   \n",
       "25         entropy               5               log2                 75   \n",
       "26         entropy               5               log2                100   \n",
       "27         entropy               6               auto                 50   \n",
       "28         entropy               6               auto                 75   \n",
       "29         entropy               6               auto                100   \n",
       "..             ...             ...                ...                ...   \n",
       "42            gini               3               log2                 50   \n",
       "43            gini               3               log2                 75   \n",
       "44            gini               3               log2                100   \n",
       "45            gini               4               auto                 50   \n",
       "46            gini               4               auto                 75   \n",
       "47            gini               4               auto                100   \n",
       "48            gini               4               sqrt                 50   \n",
       "49            gini               4               sqrt                 75   \n",
       "50            gini               4               sqrt                100   \n",
       "51            gini               4               log2                 50   \n",
       "52            gini               4               log2                 75   \n",
       "53            gini               4               log2                100   \n",
       "54            gini               5               auto                 50   \n",
       "55            gini               5               auto                 75   \n",
       "56            gini               5               auto                100   \n",
       "57            gini               5               sqrt                 50   \n",
       "58            gini               5               sqrt                 75   \n",
       "59            gini               5               sqrt                100   \n",
       "60            gini               5               log2                 50   \n",
       "61            gini               5               log2                 75   \n",
       "62            gini               5               log2                100   \n",
       "63            gini               6               auto                 50   \n",
       "64            gini               6               auto                 75   \n",
       "65            gini               6               auto                100   \n",
       "66            gini               6               sqrt                 50   \n",
       "67            gini               6               sqrt                 75   \n",
       "68            gini               6               sqrt                100   \n",
       "69            gini               6               log2                 50   \n",
       "70            gini               6               log2                 75   \n",
       "71            gini               6               log2                100   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0   {'criterion': 'entropy', 'max_depth': 3, 'max_...               55   \n",
       "1   {'criterion': 'entropy', 'max_depth': 3, 'max_...               38   \n",
       "2   {'criterion': 'entropy', 'max_depth': 3, 'max_...               63   \n",
       "3   {'criterion': 'entropy', 'max_depth': 3, 'max_...               51   \n",
       "4   {'criterion': 'entropy', 'max_depth': 3, 'max_...               30   \n",
       "5   {'criterion': 'entropy', 'max_depth': 3, 'max_...               44   \n",
       "6   {'criterion': 'entropy', 'max_depth': 3, 'max_...               72   \n",
       "7   {'criterion': 'entropy', 'max_depth': 3, 'max_...               66   \n",
       "8   {'criterion': 'entropy', 'max_depth': 3, 'max_...               66   \n",
       "9   {'criterion': 'entropy', 'max_depth': 4, 'max_...               39   \n",
       "10  {'criterion': 'entropy', 'max_depth': 4, 'max_...               26   \n",
       "11  {'criterion': 'entropy', 'max_depth': 4, 'max_...               36   \n",
       "12  {'criterion': 'entropy', 'max_depth': 4, 'max_...               46   \n",
       "13  {'criterion': 'entropy', 'max_depth': 4, 'max_...               30   \n",
       "14  {'criterion': 'entropy', 'max_depth': 4, 'max_...               32   \n",
       "15  {'criterion': 'entropy', 'max_depth': 4, 'max_...               69   \n",
       "16  {'criterion': 'entropy', 'max_depth': 4, 'max_...               60   \n",
       "17  {'criterion': 'entropy', 'max_depth': 4, 'max_...               58   \n",
       "18  {'criterion': 'entropy', 'max_depth': 5, 'max_...               20   \n",
       "19  {'criterion': 'entropy', 'max_depth': 5, 'max_...               15   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'max_...               22   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'max_...               29   \n",
       "22  {'criterion': 'entropy', 'max_depth': 5, 'max_...               12   \n",
       "23  {'criterion': 'entropy', 'max_depth': 5, 'max_...               22   \n",
       "24  {'criterion': 'entropy', 'max_depth': 5, 'max_...               59   \n",
       "25  {'criterion': 'entropy', 'max_depth': 5, 'max_...               50   \n",
       "26  {'criterion': 'entropy', 'max_depth': 5, 'max_...               43   \n",
       "27  {'criterion': 'entropy', 'max_depth': 6, 'max_...               17   \n",
       "28  {'criterion': 'entropy', 'max_depth': 6, 'max_...                1   \n",
       "29  {'criterion': 'entropy', 'max_depth': 6, 'max_...                7   \n",
       "..                                                ...              ...   \n",
       "42  {'criterion': 'gini', 'max_depth': 3, 'max_fea...               70   \n",
       "43  {'criterion': 'gini', 'max_depth': 3, 'max_fea...               65   \n",
       "44  {'criterion': 'gini', 'max_depth': 3, 'max_fea...               61   \n",
       "45  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               35   \n",
       "46  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               33   \n",
       "47  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               14   \n",
       "48  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               28   \n",
       "49  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               19   \n",
       "50  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               21   \n",
       "51  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               71   \n",
       "52  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               63   \n",
       "53  {'criterion': 'gini', 'max_depth': 4, 'max_fea...               54   \n",
       "54  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               25   \n",
       "55  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               27   \n",
       "56  {'criterion': 'gini', 'max_depth': 5, 'max_fea...                5   \n",
       "57  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               16   \n",
       "58  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               10   \n",
       "59  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               22   \n",
       "60  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               68   \n",
       "61  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               42   \n",
       "62  {'criterion': 'gini', 'max_depth': 5, 'max_fea...               56   \n",
       "63  {'criterion': 'gini', 'max_depth': 6, 'max_fea...                8   \n",
       "64  {'criterion': 'gini', 'max_depth': 6, 'max_fea...                9   \n",
       "65  {'criterion': 'gini', 'max_depth': 6, 'max_fea...                4   \n",
       "66  {'criterion': 'gini', 'max_depth': 6, 'max_fea...               17   \n",
       "67  {'criterion': 'gini', 'max_depth': 6, 'max_fea...                6   \n",
       "68  {'criterion': 'gini', 'max_depth': 6, 'max_fea...                2   \n",
       "69  {'criterion': 'gini', 'max_depth': 6, 'max_fea...               62   \n",
       "70  {'criterion': 'gini', 'max_depth': 6, 'max_fea...               48   \n",
       "71  {'criterion': 'gini', 'max_depth': 6, 'max_fea...               46   \n",
       "\n",
       "         ...         split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0        ...                  0.676545            0.745397           0.651143   \n",
       "1        ...                  0.678239            0.750476           0.665538   \n",
       "2        ...                  0.655377            0.754074           0.654530   \n",
       "3        ...                  0.660457            0.744974           0.670618   \n",
       "4        ...                  0.676545            0.751323           0.670618   \n",
       "5        ...                  0.670618            0.757672           0.661304   \n",
       "6        ...                  0.662151            0.744127           0.638442   \n",
       "7        ...                  0.660457            0.745185           0.653683   \n",
       "8        ...                  0.646909            0.740952           0.652837   \n",
       "9        ...                  0.693480            0.788571           0.673158   \n",
       "10       ...                  0.691787            0.811005           0.663844   \n",
       "11       ...                  0.703641            0.797672           0.661304   \n",
       "12       ...                  0.695174            0.799153           0.669771   \n",
       "13       ...                  0.685013            0.798730           0.665538   \n",
       "14       ...                  0.683319            0.803810           0.674852   \n",
       "15       ...                  0.651990            0.765503           0.646909   \n",
       "16       ...                  0.668078            0.783915           0.647756   \n",
       "17       ...                  0.672312            0.789630           0.644369   \n",
       "18       ...                  0.687553            0.831534           0.678239   \n",
       "19       ...                  0.696867            0.854180           0.674005   \n",
       "20       ...                  0.686706            0.846138           0.685859   \n",
       "21       ...                  0.685013            0.832169           0.676545   \n",
       "22       ...                  0.698561            0.856931           0.679932   \n",
       "23       ...                  0.694327            0.848254           0.675699   \n",
       "24       ...                  0.679086            0.819471           0.646909   \n",
       "25       ...                  0.685013            0.836190           0.651990   \n",
       "26       ...                  0.687553            0.834921           0.665538   \n",
       "27       ...                  0.697714            0.885291           0.678239   \n",
       "28       ...                  0.715495            0.890582           0.685859   \n",
       "29       ...                  0.703641            0.896720           0.679086   \n",
       "..       ...                       ...                 ...                ...   \n",
       "42       ...                  0.657070            0.750476           0.640982   \n",
       "43       ...                  0.686706            0.749841           0.623201   \n",
       "44       ...                  0.671465            0.755556           0.659610   \n",
       "45       ...                  0.685859            0.787937           0.666384   \n",
       "46       ...                  0.686706            0.799153           0.654530   \n",
       "47       ...                  0.693480            0.792169           0.680779   \n",
       "48       ...                  0.698561            0.790899           0.677392   \n",
       "49       ...                  0.705334            0.794286           0.675699   \n",
       "50       ...                  0.697714            0.798307           0.676545   \n",
       "51       ...                  0.658764            0.787513           0.635055   \n",
       "52       ...                  0.662997            0.790053           0.647756   \n",
       "53       ...                  0.675699            0.790688           0.657917   \n",
       "54       ...                  0.713802            0.830476           0.662151   \n",
       "55       ...                  0.685013            0.844656           0.673158   \n",
       "56       ...                  0.700254            0.852487           0.675699   \n",
       "57       ...                  0.703641            0.840212           0.685859   \n",
       "58       ...                  0.691787            0.842963           0.684166   \n",
       "59       ...                  0.701948            0.847407           0.672312   \n",
       "60       ...                  0.672312            0.826243           0.635902   \n",
       "61       ...                  0.692633            0.835556           0.663844   \n",
       "62       ...                  0.674005            0.836190           0.660457   \n",
       "63       ...                  0.687553            0.905608           0.702794   \n",
       "64       ...                  0.698561            0.898413           0.680779   \n",
       "65       ...                  0.693480            0.893757           0.688400   \n",
       "66       ...                  0.698561            0.882751           0.674005   \n",
       "67       ...                  0.699407            0.906032           0.692633   \n",
       "68       ...                  0.709568            0.903492           0.696867   \n",
       "69       ...                  0.646063            0.878730           0.652837   \n",
       "70       ...                  0.672312            0.888042           0.651143   \n",
       "71       ...                  0.662997            0.890582           0.660457   \n",
       "\n",
       "    split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0             0.748148           0.686706            0.763810      0.029418   \n",
       "1             0.756825           0.720576            0.771217      0.049149   \n",
       "2             0.764021           0.674852            0.753439      0.055501   \n",
       "3             0.768677           0.689246            0.754074      0.079387   \n",
       "4             0.765714           0.701101            0.758942      0.080133   \n",
       "5             0.765714           0.703641            0.755767      0.086849   \n",
       "6             0.759788           0.674005            0.745397      0.041386   \n",
       "7             0.754497           0.675699            0.750265      0.039103   \n",
       "8             0.757884           0.667231            0.744974      0.045068   \n",
       "9             0.779259           0.682472            0.792381      0.033159   \n",
       "10            0.799577           0.705334            0.790053      0.039329   \n",
       "11            0.806349           0.697714            0.791323      0.090866   \n",
       "12            0.797672           0.691787            0.785185      0.026727   \n",
       "13            0.795132           0.698561            0.807196      0.045994   \n",
       "14            0.800212           0.693480            0.801905      0.049031   \n",
       "15            0.773333           0.665538            0.775661      0.041985   \n",
       "16            0.790053           0.672312            0.776508      0.038002   \n",
       "17            0.791534           0.699407            0.790053      0.056119   \n",
       "18            0.840423           0.710415            0.835556      0.029071   \n",
       "19            0.840635           0.713802            0.839153      0.034958   \n",
       "20            0.852063           0.699407            0.852487      0.056577   \n",
       "21            0.836190           0.696867            0.833439      0.025829   \n",
       "22            0.842751           0.723963            0.837249      0.066653   \n",
       "23            0.851217           0.705334            0.842751      0.054103   \n",
       "24            0.817354           0.674005            0.821376      0.035995   \n",
       "25            0.832804           0.690093            0.827090      0.039287   \n",
       "26            0.838942           0.679086            0.830899      0.050142   \n",
       "27            0.892275           0.691787            0.887407      0.029000   \n",
       "28            0.890582           0.716342            0.892698      0.038485   \n",
       "29            0.897143           0.707875            0.883810      0.056035   \n",
       "..                 ...                ...                 ...           ...   \n",
       "42            0.742857           0.672312            0.743069      0.024231   \n",
       "43            0.739048           0.679086            0.752169      0.081506   \n",
       "44            0.749206           0.671465            0.751958      0.050647   \n",
       "45            0.782434           0.700254            0.800423      0.024837   \n",
       "46            0.800635           0.705334            0.794921      0.034933   \n",
       "47            0.796825           0.709568            0.798730      0.053463   \n",
       "48            0.786032           0.690093            0.780529      0.027722   \n",
       "49            0.792169           0.695174            0.800423      0.036544   \n",
       "50            0.804656           0.707028            0.811217      0.046908   \n",
       "51            0.784339           0.665538            0.773333      0.023121   \n",
       "52            0.785608           0.695174            0.794709      0.036377   \n",
       "53            0.794497           0.680779            0.792169      0.057160   \n",
       "54            0.838307           0.696867            0.834497      0.023232   \n",
       "55            0.844656           0.696020            0.843598      0.036018   \n",
       "56            0.853757           0.713802            0.846772      0.048063   \n",
       "57            0.841058           0.699407            0.829841      0.031631   \n",
       "58            0.847407           0.701948            0.838730      0.038932   \n",
       "59            0.843175           0.695174            0.842751      0.049603   \n",
       "60            0.830053           0.673158            0.825608      0.024328   \n",
       "61            0.835979           0.696020            0.833228      0.035325   \n",
       "62            0.842328           0.684166            0.837460      0.047034   \n",
       "63            0.894180           0.689246            0.896720      0.025570   \n",
       "64            0.898413           0.712955            0.898201      0.032769   \n",
       "65            0.903492           0.707028            0.894603      0.047667   \n",
       "66            0.888889           0.702794            0.890370      0.023477   \n",
       "67            0.900741           0.710415            0.901587      0.037159   \n",
       "68            0.897989           0.709568            0.905608      0.052279   \n",
       "69            0.877249           0.680779            0.874074      0.048699   \n",
       "70            0.879788           0.701948            0.893968      0.034170   \n",
       "71            0.884868           0.692633            0.895238      0.047795   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.002379        0.011671         0.006891  \n",
       "1         0.001134        0.021882         0.007984  \n",
       "2         0.001649        0.008680         0.007916  \n",
       "3         0.001290        0.012357         0.008874  \n",
       "4         0.001711        0.012148         0.007722  \n",
       "5         0.001612        0.014199         0.005995  \n",
       "6         0.001831        0.017853         0.010922  \n",
       "7         0.001684        0.008320         0.006970  \n",
       "8         0.001568        0.016869         0.010317  \n",
       "9         0.000789        0.007436         0.005349  \n",
       "10        0.001691        0.014120         0.006930  \n",
       "11        0.001844        0.015841         0.006033  \n",
       "12        0.002047        0.017429         0.007582  \n",
       "13        0.001011        0.012286         0.005864  \n",
       "14        0.000597        0.006186         0.005689  \n",
       "15        0.001446        0.008985         0.006587  \n",
       "16        0.001683        0.011297         0.006616  \n",
       "17        0.001771        0.018607         0.005011  \n",
       "18        0.001580        0.012078         0.004586  \n",
       "19        0.001339        0.012763         0.006416  \n",
       "20        0.001922        0.006260         0.002685  \n",
       "21        0.002626        0.009370         0.002945  \n",
       "22        0.001744        0.016273         0.008379  \n",
       "23        0.002066        0.011565         0.003459  \n",
       "24        0.001216        0.013249         0.005076  \n",
       "25        0.001708        0.013212         0.005812  \n",
       "26        0.001597        0.010515         0.003333  \n",
       "27        0.001345        0.009038         0.004551  \n",
       "28        0.002224        0.012091         0.002663  \n",
       "29        0.000967        0.010287         0.004854  \n",
       "..             ...             ...              ...  \n",
       "42        0.002287        0.010998         0.004008  \n",
       "43        0.001585        0.024137         0.005148  \n",
       "44        0.000197        0.004352         0.003412  \n",
       "45        0.001896        0.014120         0.007862  \n",
       "46        0.002050        0.016768         0.004012  \n",
       "47        0.000737        0.009465         0.006627  \n",
       "48        0.000538        0.007104         0.004890  \n",
       "49        0.002353        0.009772         0.005425  \n",
       "50        0.000489        0.010298         0.007113  \n",
       "51        0.000226        0.012368         0.007815  \n",
       "52        0.002074        0.016258         0.005364  \n",
       "53        0.001396        0.007775         0.006216  \n",
       "54        0.001169        0.017286         0.003707  \n",
       "55        0.001198        0.010001         0.002631  \n",
       "56        0.001545        0.013044         0.003305  \n",
       "57        0.001975        0.007631         0.004130  \n",
       "58        0.002337        0.007304         0.003507  \n",
       "59        0.001125        0.010061         0.004575  \n",
       "60        0.002300        0.013835         0.004668  \n",
       "61        0.000695        0.013429         0.001625  \n",
       "62        0.002280        0.012903         0.005287  \n",
       "63        0.001677        0.009924         0.007538  \n",
       "64        0.001546        0.010275         0.003904  \n",
       "65        0.001113        0.008407         0.004965  \n",
       "66        0.001311        0.010484         0.003261  \n",
       "67        0.001554        0.005943         0.005680  \n",
       "68        0.002034        0.007835         0.002920  \n",
       "69        0.001374        0.017109         0.002788  \n",
       "70        0.001389        0.016238         0.005983  \n",
       "71        0.000278        0.015830         0.006629  \n",
       "\n",
       "[72 rows x 24 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "min_leaf_samples:  300\n",
      "train score:  0.751269895022\n",
      "val score:  0.704288164666\n",
      "oob score:  0.699458178124\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, bootstrap=True,\n",
    "                                   max_depth=4, min_samples_leaf=200)\n",
    "model2.fit(train_X, train_y)\n",
    "print('\\nmin_leaf_samples: ', samples)\n",
    "print('train score: ', model2.score(train_X, train_y))\n",
    "print('val score: ', model2.score(val_X, val_y))\n",
    "print('oob score: ', model2.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
